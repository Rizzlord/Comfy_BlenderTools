from pathlib import Path

new_block = """class MultiviewTextureBake:\n    PROJECTION_MODES = [\"orthographic\", \"perspective\"]\n    RESOLUTIONS = [\"512\", \"1024\", \"2048\", \"4096\", \"8192\"]\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"mesh\": (\"TRIMESH\",),\n                \"multiview_images\": (\"IMAGE\",),\n                \"projection_mode\": (cls.PROJECTION_MODES, {\"default\": \"orthographic\"}),\n                \"texture_resolution\": (cls.RESOLUTIONS, {\"default\": \"2048\"}),\n                \"margin\": (\"INT\", {\"default\": 16, \"min\": 0, \"max\": 4096}),\n                \"use_gpu\": (\"BOOLEAN\", {\"default\": True}),\n                \"use_seqtex_mv\": (\"BOOLEAN\", {\"default\": False}),\n                \"use_depth_occlusion\": (\"BOOLEAN\", {\"default\": True}),\n                \"blend_sharpness\": (\"FLOAT\", {\"default\": 4.0, \"min\": 0.1, \"max\": 16.0, \"step\": 0.1}),\n                \"angle_cutoff\": (\"FLOAT\", {\"default\": 90.0, \"min\": 0.0, \"max\": 180.0, \"step\": 0.5}),\n                \"perspective_fov\": (\"FLOAT\", {\"default\": 50.0, \"min\": 1.0, \"max\": 120.0, \"step\": 0.1}),\n                \"orthographic_width\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.1, \"max\": 10.0, \"step\": 0.01}),\n                \"orthographic_height\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.1, \"max\": 10.0, \"step\": 0.01}),\n                \"perspective_width\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.1, \"max\": 10.0, \"step\": 0.01}),\n                \"perspective_height\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.1, \"max\": 10.0, \"step\": 0.01}),\n                \"brightness\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 2.0, \"step\": 0.01}),\n                \"contrast\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 4.0, \"step\": 0.01}),\n                \"saturation\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 2.0, \"step\": 0.01}),\n            },\n            \"optional\": {\n                \"camera_config\": (\"HY3DCAMERA\",),\n                \"seqtex_rotation_offset\": (\"FLOAT\", {\"default\": 0.0, \"min\": -360.0, \"max\": 360.0, \"step\": 1.0}),\n                \"seqtex_view_preset\": ([\"\"] + SEQ_TEX_VIEW_PRESETS, {\"default\": \"\"}),\n                \"multiview_masks\": (\"MASK\",),\n            }\n        }\n\n    RETURN_TYPES = (\"TRIMESH\", \"IMAGE\")\n    RETURN_NAMES = (\"mesh_with_vertex_colors\", \"color_map\")\n    FUNCTION = \"bake\"\n    CATEGORY = \"Comfy_BlenderTools/VertexBake\"\n\n    def bake(\n        self,\n        mesh,\n        multiview_images,\n        projection_mode,\n        texture_resolution,\n        margin,\n        use_gpu,\n        use_seqtex_mv,\n        use_depth_occlusion,\n        blend_sharpness,\n        angle_cutoff,\n        perspective_fov,\n        orthographic_width,\n        orthographic_height,\n        perspective_width,\n        perspective_height,\n        brightness,\n        contrast,\n        saturation,\n        camera_config=None,\n        seqtex_rotation_offset=0.0,\n        seqtex_view_preset=\"\",\n        multiview_masks=None,\n    ):\n        has_uv = hasattr(mesh.visual, 'uv') and mesh.visual.uv is not None and len(mesh.visual.uv) > 0\n        if not has_uv:\n            raise ValueError(\"Mesh has no UV map. Please use the BlenderUnwrap node first.\")\n\n        num_views = _infer_multiview_count(multiview_images)\n        if num_views <= 0:\n            raise ValueError(\"At least one multiview image is required.\")\n\n        effective_camera_config = camera_config\n        effective_perspective_fov = perspective_fov\n        effective_orthographic_width = orthographic_width\n        effective_orthographic_height = orthographic_height\n        multiview_images_to_use = multiview_images\n        multiview_masks_to_use = multiview_masks\n\n        if use_seqtex_mv:\n            preset = (seqtex_view_preset or \"\").strip()\n            if not preset:\n                guess = str(num_views)\n                preset = guess if guess in SEQ_TEX_VIEW_PRESETS else SEQ_TEX_VIEW_PRESETS[-1]\n            if preset not in SEQ_TEX_VIEW_PRESETS:\n                raise ValueError(f\"Unsupported SeqTex view preset '{preset}'.\")\n            azims, elevs = _seqtex_view_preset_angles(preset, 0.0, azimuth_offset=seqtex_rotation_offset)\n            required_views = len(azims)\n            multiview_images_to_use, multiview_masks_to_use = _trim_multiview_inputs(\n                multiview_images,\n                multiview_masks,\n                required_views,\n                \"SeqTex multiview images\",\n            )\n            effective_camera_config = _build_seqtex_camera_config(\n                mesh,\n                azims,\n                elevs,\n                camera_lens=50.0,\n                camera_sensor_width=36.0,\n                ortho_scale=1.2,\n            )\n            effective_perspective_fov = float(np.degrees(2.0 * np.arctan(36.0 / (2.0 * 50.0))))\n            effective_orthographic_width = 2.1\n            effective_orthographic_height = 2.1\n\n        textured_mesh = project_multiview_vertex_colors(\n            mesh,\n            multiview_images_to_use,\n            projection_mode,\n            blend_sharpness,\n            angle_cutoff,\n            effective_perspective_fov,\n            effective_orthographic_width,\n            effective_orthographic_height,\n            perspective_width,\n            perspective_height,\n            camera_config=effective_camera_config,\n            fill_unpainted=True,\n            multiview_masks=multiview_masks_to_use,\n            use_depth_occlusion=use_depth_occlusion,\n        )\n\n        color_map_tensor = self._bake_vertex_colors_to_texture(\n            textured_mesh,\n            resolution=int(texture_resolution),\n            margin=margin,\n            use_gpu=use_gpu,\n        )\n\n        color_map_tensor = color_map_tensor * brightness\n        color_map_tensor = (color_map_tensor - 0.5) * contrast + 0.5\n        if saturation != 1.0:\n            luma_weights = color_map_tensor.new_tensor([0.299, 0.587, 0.114])\n            luminance = (color_map_tensor * luma_weights).sum(dim=-1, keepdim=True)\n            color_map_tensor = luminance + (color_map_tensor - luminance) * saturation\n        color_map_tensor = torch.clamp(color_map_tensor, 0.0, 1.0)\n\n        return (textured_mesh, color_map_tensor)\n\n    def _bake_vertex_colors_to_texture(self, mesh, resolution, margin, use_gpu):\n        dummy_image = torch.zeros((1, 64, 64, 3), dtype=torch.float32)\n\n        with tempfile.TemporaryDirectory() as temp_dir:\n            mesh_path = os.path.join(temp_dir, \"mesh.glb\")\n            texture_path = os.path.join(temp_dir, \"color_map.png\")\n            script_path = os.path.join(temp_dir, \"s.py\")\n\n            mesh.export(file_obj=mesh_path)\n\n            params = {\n                \"mesh_path\": mesh_path,\n                \"texture_path\": texture_path,\n                \"resolution\": int(resolution),\n                \"margin\": int(margin),\n                \"use_gpu\": use_gpu,\n            }\n\n            script = f'''\nimport bpy, sys, os, traceback\np = {{ {", ".join(f'"{{k}}": r"{{v}}"' if isinstance(v, str) else f'"{{k}}": {{v}}' for k, v in params.items())} }}\n\ndef setup_gpu():\n    if not p['use_gpu']:\n        bpy.context.scene.cycles.device = 'CPU'\n        return\n    try:\n        prefs = bpy.context.preferences.addons['cycles'].preferences\n        prefs.compute_device_type = 'NONE'\n        device types = ['OPTIX', 'CUDA', 'HIP', 'METAL', 'ONEAPI']\n        for device_type in device_types:\n            if hasattr(prefs, 'get_devices_for_type'):\n                devices = prefs.get_devices_for_type(device_type)\n            else:\n                devices = []\n            if devices:\n                prefs.compute_device_type = device_type\n                print(f"Found and set compute device type to: {{device_type}}")\n                break\n        prefs.get_devices()\n        for device in prefs.devices:\n            device use???
